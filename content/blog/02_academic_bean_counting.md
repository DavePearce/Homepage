---
date: 2020-11-17
title: "Academic Bean Counting and PL Research"
draft: true
#metaimg: "images/2020/semver.png"
#metatxt: "Semantic versioning is a low fidelity communication channel.  However, tooling could be used to improve this situation, such as through static analysis"
#twitterimgalt: "Image showing example dependencies with versions in a build file."
twittersite: "@whileydave"
---

An interesting [keynote](https://youtu.be/LaaUKWXHpNs) given recently
at [SplashCon
2020](https://2020.splashcon.org/details/splash-2020-splash-keynotes/14/Fitzcarraldo-or-How-to-Hack-Academia-to-Build-Stuff)
talked about "academic bean counting" and its effect on research in
programming languages.  The summary (roughly speaking) is that
focusing on how many papers an academic produces (i.e. bean counting)
detracts from their ability to invest in the long term infrastructure
building needed for high quality research in programming languages
(and, presumably, other similar fields).  A key excerpt from the talk
abstract:

> "*What does a movie about a monomaniacal quest to build an opera
> house in the Amazon Basin has to do with science? Programming
> language research is at a crossroads. While formal language
> techniques are advancing steadily, the transfer of ideas to practice
> is much slower. Applied research is based on experimentation which
> is becoming prohibitively onerous.*"

I suppose the big question here is: *why is "bean counting" really a
problem?* Yes, academics need to disseminate their work --- otherwise,
what's the point?  And, yes, peer review remains the de facto
mechanism for ensuring some degree of quality (but let's not get
started on that!).

The problem with bean counting is that incentivizes against risk.
*Need three years to bootstrap your project before you can start
producing papers --- no way!* Certainly, if you're on tenure track
then you just don't have time for this.  Luckily some academics do
make this kind of investment, but it often comes at a personal cost.

* We've all heard of "publish or perish".  Minimal publishable unit.
-- https://physicstoday.scitation.org/doi/10.1063/1.1712503
-- https://medium.com/quote-of-the-week/crises-in-academia-today-74fcbe1a80f4
-- https://www.sixthtone.com/news/1003146/publish-or-perish-the-dark-world-of-chinese-academic-publishing

* PL is a dying field.  Artifact evaluation.

* Examples of big projects?  Jikes. Scala. Soot. Why3.

* Doesn't incentivize refactoring or quality.

* bigger problem of a economic and competitive environment.  Big
  sharks (i.e. larger fields) win.  PL is not a large field.

* Competition from big research companies.

* Short terminism?  "Much recent work in strategy and popular
discussion suggests that an excessive focus on “managing the numbers”
--delivering quarterly earnings at the expense of longer term
investments--makes it difficult for firms to make the investments
necessary to build competitive advantage" Paper: Making the Numbers?
“Short Termism” & The Puzzle of Only Occasional Disaster

* Conclusion.  In the econimics of the world, PL research is dying.

https://www.universityworldnews.com/post.php?story=20120621232911143
